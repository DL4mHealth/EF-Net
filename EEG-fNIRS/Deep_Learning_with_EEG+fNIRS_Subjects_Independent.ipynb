{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b69b9c99",
      "metadata": {
        "id": "b69b9c99"
      },
      "source": [
        "# Subjects Independent Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca1b565",
      "metadata": {
        "id": "7ca1b565"
      },
      "outputs": [],
      "source": [
        "#total subjects separated into 80-20 train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JtzLH714brDJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtzLH714brDJ",
        "outputId": "fb42ffc5-0890-4835-931a-ec985b38a7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## FOR GOOGLE COLLAB ONLY\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EiodGNuLbrtx",
      "metadata": {
        "id": "EiodGNuLbrtx"
      },
      "outputs": [],
      "source": [
        "## FOR GOOGLE COLLAB ONLY\n",
        "#extract EEG & FNIRS data\n",
        "#cp /content/drive/MyDrive/Data.zip .\n",
        "#!unzip -qq Data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9efbd3a0",
      "metadata": {
        "id": "9efbd3a0"
      },
      "source": [
        "In this notebook, we will apply EF-Net classifier to Hybrid EEG + fNIRS data with the data split in a Subject Independent setting. We also have the Deep Learning baselines here, that can be implemented using the 'baseline_model' boolean set to True, and further the 'resnet' boolean which indicates a resnet baseline to be used, if resnet==False, then the VGG baseline shall be implemented."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e0e1d44",
      "metadata": {
        "id": "5e0e1d44"
      },
      "source": [
        "The current settings in this file will run the EF-Net model. (baseline_model==False)\n",
        "Deep learning parameters were set according to the table in the appendix of our published paper: [EF-Net: Mental State Recognition by Analyzing Multimodal EEG-fNIRS via CNN](https://doi.org/10.3390/s24061889)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7400f7f",
      "metadata": {
        "id": "a7400f7f"
      },
      "source": [
        "The dataset we have used is called: Simultaneous Acquisition of EEG and NIRS during Cognitive Tasks for\n",
        "an Open Access Dataset,\n",
        "    and is available here: https://doc.ml.tu-berlin.de/simultaneous_EEG_NIRS/. We are using Dataset C for classification.\n",
        "    There is 72 fNIRS channels and 30 EEG channels. The dataset has 26 subjects in total. Each subject has data of 60 trials: which includes 3 sessions per subject, each session has 20 trials, each trial has 10 Word Generation tasks, and 10 Baseline tasks. This brings each subject to a total of 60 trials of either WG or BL tasks, performed in random order. Here we will further use those 60 trials to create 360 samples per subject, by using a sliding window technique across each trial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcca0812",
      "metadata": {
        "id": "dcca0812"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from data_preprocess import extract_subj_indep\n",
        "import hybrid_model_structures as models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecd721fc",
      "metadata": {
        "id": "ecd721fc"
      },
      "source": [
        "### Inputs - enter here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a51ed2c",
      "metadata": {
        "id": "9a51ed2c"
      },
      "outputs": [],
      "source": [
        "#INPUT\n",
        "\n",
        "#subjects directory path\n",
        "#The data should be extracted in the same directory as this script.\n",
        "dir_path_f = \"./FNIRS_data/FNIRS2/NIRS_01-26_MATLAB/\"\n",
        "dir_path_e=\"./EEG_data/EEG2/EEG_01-26_MATLAB/\"\n",
        "\n",
        "#######################\n",
        "#Deep Learning settings:\n",
        "\n",
        "baseline_model=False\n",
        "resnet=False\n",
        "if baseline_model:\n",
        "    lr=1e-5\n",
        "    EPOCHS=100\n",
        "else:\n",
        "    lr=5e-5\n",
        "    EPOCHS=40\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "RANDOM_STATE=38"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9438d8ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9438d8ad",
        "outputId": "fd39fc90-0947-4e74-e0cc-cf5a761d0429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject Count: 26\n",
            "[14, 17, 6, 8, 5, 12, 9, 0, 24, 20, 7, 18, 3, 23, 15, 13, 22, 10, 16, 25, 2, 4, 19, 21, 11, 1]\n",
            "fnirs len 20245\n",
            "eeg len 372182\n",
            "Subject  15 is done. Length of X_train,X_test is now: 360 0 and length of Y_train, Y_test is:  360 0\n",
            "fnirs len 20295\n",
            "eeg len 372437\n",
            "Subject  18 is done. Length of X_train,X_test is now: 720 0 and length of Y_train, Y_test is:  720 0\n",
            "fnirs len 20145\n",
            "eeg len 371449\n",
            "Subject  7 is done. Length of X_train,X_test is now: 1080 0 and length of Y_train, Y_test is:  1080 0\n",
            "fnirs len 20241\n",
            "eeg len 371618\n",
            "Subject  9 is done. Length of X_train,X_test is now: 1440 0 and length of Y_train, Y_test is:  1440 0\n",
            "fnirs len 20191\n",
            "eeg len 371874\n",
            "Subject  6 is done. Length of X_train,X_test is now: 1800 0 and length of Y_train, Y_test is:  1800 0\n",
            "fnirs len 20210\n",
            "eeg len 371163\n",
            "Subject  13 is done. Length of X_train,X_test is now: 2160 0 and length of Y_train, Y_test is:  2160 0\n",
            "fnirs len 20191\n",
            "eeg len 371869\n",
            "Subject  10 is done. Length of X_train,X_test is now: 2520 0 and length of Y_train, Y_test is:  2520 0\n",
            "fnirs len 20107\n",
            "eeg len 371283\n",
            "Subject  1 is done. Length of X_train,X_test is now: 2880 0 and length of Y_train, Y_test is:  2880 0\n",
            "fnirs len 20230\n",
            "eeg len 371934\n",
            "Subject  25 is done. Length of X_train,X_test is now: 3240 0 and length of Y_train, Y_test is:  3240 0\n",
            "fnirs len 20169\n",
            "eeg len 371132\n",
            "Subject  21 is done. Length of X_train,X_test is now: 3600 0 and length of Y_train, Y_test is:  3600 0\n",
            "fnirs len 20192\n",
            "eeg len 372097\n",
            "Subject  8 is done. Length of X_train,X_test is now: 3960 0 and length of Y_train, Y_test is:  3960 0\n",
            "fnirs len 20122\n",
            "eeg len 370551\n",
            "Subject  19 is done. Length of X_train,X_test is now: 4320 0 and length of Y_train, Y_test is:  4320 0\n",
            "fnirs len 20115\n",
            "eeg len 371949\n",
            "Subject  4 is done. Length of X_train,X_test is now: 4680 0 and length of Y_train, Y_test is:  4680 0\n",
            "fnirs len 20253\n",
            "eeg len 372602\n",
            "Subject  24 is done. Length of X_train,X_test is now: 5040 0 and length of Y_train, Y_test is:  5040 0\n",
            "fnirs len 20253\n",
            "eeg len 372944\n",
            "Subject  16 is done. Length of X_train,X_test is now: 5400 0 and length of Y_train, Y_test is:  5400 0\n",
            "fnirs len 20299\n",
            "eeg len 373725\n",
            "Subject  14 is done. Length of X_train,X_test is now: 5760 0 and length of Y_train, Y_test is:  5760 0\n",
            "fnirs len 20203\n",
            "eeg len 372360\n",
            "Subject  23 is done. Length of X_train,X_test is now: 6120 0 and length of Y_train, Y_test is:  6120 0\n",
            "fnirs len 20211\n",
            "eeg len 371851\n",
            "Subject  11 is done. Length of X_train,X_test is now: 6480 0 and length of Y_train, Y_test is:  6480 0\n",
            "fnirs len 20207\n",
            "eeg len 372461\n",
            "Subject  17 is done. Length of X_train,X_test is now: 6840 0 and length of Y_train, Y_test is:  6840 0\n",
            "fnirs len 20157\n",
            "eeg len 371154\n",
            "Subject  26 is done. Length of X_train,X_test is now: 7200 0 and length of Y_train, Y_test is:  7200 0\n",
            "fnirs len 20269\n",
            "eeg len 373808\n",
            "Subject  3 is done. Length of X_train,X_test is now: 7200 360 and length of Y_train, Y_test is:  7200 360\n",
            "fnirs len 20237\n",
            "eeg len 372647\n",
            "Subject  5 is done. Length of X_train,X_test is now: 7200 720 and length of Y_train, Y_test is:  7200 720\n",
            "fnirs len 20446\n",
            "eeg len 372787\n",
            "Subject  20 is done. Length of X_train,X_test is now: 7200 1080 and length of Y_train, Y_test is:  7200 1080\n",
            "fnirs len 20169\n",
            "eeg len 370973\n",
            "Subject  22 is done. Length of X_train,X_test is now: 7200 1440 and length of Y_train, Y_test is:  7200 1440\n",
            "fnirs len 20215\n",
            "eeg len 370962\n",
            "Subject  12 is done. Length of X_train,X_test is now: 7200 1800 and length of Y_train, Y_test is:  7200 1800\n",
            "fnirs len 20219\n",
            "eeg len 371416\n",
            "Subject  2 is done. Length of X_train,X_test is now: 7200 2160 and length of Y_train, Y_test is:  7200 2160\n",
            "Xeeg_train (7200, 500, 30)\n",
            "Xfnirs_train (7200, 25, 72)\n",
            "Xeeg_test (2160, 500, 30)\n",
            "Xfnirs_test (2160, 25, 72)\n",
            "Y_train (7200, 2)\n",
            "Y_train samples [[0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]]\n",
            "Y_test (2160, 2)\n",
            "Y_test samples [[0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n"
          ]
        }
      ],
      "source": [
        "Xeeg_train, Xfnirs_train, Y_train, Xeeg_test, Xfnirs_test, Y_test= extract_subj_indep(dir_path_e,dir_path_f,baseline_model,RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c149f0aa",
      "metadata": {
        "id": "c149f0aa"
      },
      "source": [
        "We now have an array of 360 samples per subject, with a total of 9360 samples as shown across the train and test in output above. Each sample is a 5 second window from the task data, with one second of overlap with the previous sample.  \n",
        "Secondly, we have an array Y made from the labels (y) array in session_markers from the dataset, and by appending the corresponding classes across the samples taken, we have 360 trial labels per subject in the Y array, totalling 9360 labels across all subjects' trials."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88bcbdf2",
      "metadata": {
        "id": "88bcbdf2"
      },
      "source": [
        "### Standardizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab9c8bd",
      "metadata": {
        "id": "9ab9c8bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d90d3985",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d90d3985",
        "outputId": "d40b2ba8-3876-479e-8648-2e8e7f01c0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7200, 500, 30)\n",
            "(7200, 25, 72)\n"
          ]
        }
      ],
      "source": [
        "# Standardize our signals data\n",
        "# Reshaping the data samples into 2D applying the scaling and then reshaping back\n",
        "scaler = StandardScaler()\n",
        "Xeeg_trainS = scaler.fit_transform(Xeeg_train.reshape(-1, Xeeg_train.shape[-1])).reshape(Xeeg_train.shape)\n",
        "Xeeg_testS = scaler.transform(Xeeg_test.reshape(-1, Xeeg_test.shape[-1])).reshape(Xeeg_test.shape)\n",
        "\n",
        "Xfnirs_trainS = scaler.fit_transform(Xfnirs_train.reshape(-1, Xfnirs_train.shape[-1])).reshape(Xfnirs_train.shape)\n",
        "Xfnirs_testS = scaler.transform(Xfnirs_test.reshape(-1, Xfnirs_test.shape[-1])).reshape(Xfnirs_test.shape)\n",
        "\n",
        "print(Xeeg_trainS.shape)\n",
        "print(Xfnirs_trainS.shape)\n",
        "\n",
        "#adjustment to labels to make compatible with binary_crossentropy\n",
        "Y_train=Y_train[:,0]\n",
        "Y_test=Y_test[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "521f776f",
      "metadata": {
        "id": "521f776f"
      },
      "outputs": [],
      "source": [
        "#reshaping data into correct form for input into models.\n",
        "if baseline_model:\n",
        "    Xeeg_trainS_3D=Xeeg_trainS\n",
        "    Xeeg_testS_3D=Xeeg_testS\n",
        "    Xfnirs_trainS_3D=Xfnirs_trainS\n",
        "    Xfnirs_testS_3D=Xfnirs_testS\n",
        "else:\n",
        "    #reshape into 2D and 1 channel data (3D samples list) for EF-Net.\n",
        "    Xeeg_trainS_3D=np.reshape(Xeeg_trainS,(Xeeg_trainS.shape[0],Xeeg_trainS.shape[1],Xeeg_trainS.shape[2],1))\n",
        "    Xeeg_testS_3D=np.reshape(Xeeg_testS,(Xeeg_testS.shape[0],Xeeg_testS.shape[1],Xeeg_testS.shape[2],1))\n",
        "    Xfnirs_trainS_3D=np.reshape(Xfnirs_trainS,(Xfnirs_trainS.shape[0],Xfnirs_trainS.shape[1],Xfnirs_trainS.shape[2],1))\n",
        "    Xfnirs_testS_3D=np.reshape(Xfnirs_testS,(Xfnirs_testS.shape[0],Xfnirs_testS.shape[1],Xfnirs_testS.shape[2],1))\n",
        "    Xeeg_trainS_3D.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cba1113",
      "metadata": {
        "id": "9cba1113"
      },
      "source": [
        "### Applying a deep neural network to our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60bf7b6",
      "metadata": {
        "id": "c60bf7b6"
      },
      "outputs": [],
      "source": [
        "if baseline_model:\n",
        "    hybridmodel= models.eeg_fnirs_vgg(Xeeg_trainS_3D,Xfnirs_trainS_3D,resnet)\n",
        "else:\n",
        "    hybridmodel= models.eeg_fnirs_cnn_v2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "frLtvuA2Iu1t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frLtvuA2Iu1t",
        "outputId": "16d2e480-9075-4d63-8366-2a52313d7335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 500, 30, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 494, 30, 32)          256       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 488, 30, 32)          7200      ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 482, 30, 32)          7200      ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 68, 30, 32)           0         ['conv2d_2[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 25, 72, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 68, 30, 32)           0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 22, 72, 32)           160       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 68, 30, 32)           128       ['dropout[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 19, 72, 32)           4128      ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 65, 27, 64)           32832     ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 72, 32)            0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 62, 24, 64)           65600     ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 4, 72, 32)            0         ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 59, 21, 64)           65600     ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 4, 72, 32)            128       ['dropout_3[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 5, 64)            0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 3, 71, 64)            8256      ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 14, 5, 64)            0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 2, 70, 64)            16448     ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 14, 5, 64)            256       ['dropout_1[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 1, 35, 64)            0         ['conv2d_9[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 4480)                 0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 1, 35, 64)            0         ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  1147136   ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 1, 35, 64)            256       ['dropout_4[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 256)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 2240)                 0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 128)                  286848    ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 256)                  0         ['dense_1[0][0]',             \n",
            "                                                                     'dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  65792     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 256)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 256)                  0         ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   16448     ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1)                    65        ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1757633 (6.70 MB)\n",
            "Trainable params: 1757249 (6.70 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "hybridmodel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae9ec82",
      "metadata": {
        "id": "9ae9ec82"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "hybridmodel.compile(optimizer=Adam(learning_rate=lr),loss='binary_crossentropy',metrics=['accuracy','Precision','Recall','AUC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YbI47Y5XvWFZ",
      "metadata": {
        "id": "YbI47Y5XvWFZ"
      },
      "outputs": [],
      "source": [
        "#save best model\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64060922",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64060922",
        "outputId": "d5e1af9b-07ad-410a-ee67-7658d1ebcb49",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5096 - precision: 0.5070 - recall: 0.6928 - auc: 0.5208\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50417, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 24s 72ms/step - loss: 0.6925 - accuracy: 0.5096 - precision: 0.5070 - recall: 0.6928 - auc: 0.5208 - val_loss: 0.6904 - val_accuracy: 0.5042 - val_precision: 0.5021 - val_recall: 0.9880 - val_auc: 0.6178\n",
            "Epoch 2/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5371 - precision: 0.5293 - recall: 0.6736 - auc: 0.5487\n",
            "Epoch 2: val_accuracy improved from 0.50417 to 0.50463, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 52ms/step - loss: 0.6910 - accuracy: 0.5375 - precision: 0.5295 - recall: 0.6742 - auc: 0.5490 - val_loss: 0.6894 - val_accuracy: 0.5046 - val_precision: 0.5024 - val_recall: 0.9639 - val_auc: 0.6209\n",
            "Epoch 3/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5462 - precision: 0.5390 - recall: 0.6389 - auc: 0.5619\n",
            "Epoch 3: val_accuracy improved from 0.50463 to 0.51759, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 49ms/step - loss: 0.6895 - accuracy: 0.5462 - precision: 0.5390 - recall: 0.6389 - auc: 0.5619 - val_loss: 0.6886 - val_accuracy: 0.5176 - val_precision: 0.5095 - val_recall: 0.9435 - val_auc: 0.6183\n",
            "Epoch 4/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6874 - accuracy: 0.5594 - precision: 0.5523 - recall: 0.6263 - auc: 0.5757\n",
            "Epoch 4: val_accuracy improved from 0.51759 to 0.55324, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 51ms/step - loss: 0.6875 - accuracy: 0.5592 - precision: 0.5522 - recall: 0.6261 - auc: 0.5753 - val_loss: 0.6860 - val_accuracy: 0.5532 - val_precision: 0.5315 - val_recall: 0.8991 - val_auc: 0.6176\n",
            "Epoch 5/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.5605 - precision: 0.5566 - recall: 0.6010 - auc: 0.5829\n",
            "Epoch 5: val_accuracy improved from 0.55324 to 0.57824, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.6853 - accuracy: 0.5607 - precision: 0.5561 - recall: 0.6014 - auc: 0.5834 - val_loss: 0.6805 - val_accuracy: 0.5782 - val_precision: 0.5497 - val_recall: 0.8657 - val_auc: 0.6281\n",
            "Epoch 6/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.5700 - precision: 0.5703 - recall: 0.5671 - auc: 0.5980\n",
            "Epoch 6: val_accuracy improved from 0.57824 to 0.59074, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.6822 - accuracy: 0.5696 - precision: 0.5700 - recall: 0.5664 - auc: 0.5973 - val_loss: 0.6755 - val_accuracy: 0.5907 - val_precision: 0.5592 - val_recall: 0.8574 - val_auc: 0.6386\n",
            "Epoch 7/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6794 - accuracy: 0.5787 - precision: 0.5793 - recall: 0.5755 - auc: 0.6081\n",
            "Epoch 7: val_accuracy improved from 0.59074 to 0.60787, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 51ms/step - loss: 0.6793 - accuracy: 0.5788 - precision: 0.5793 - recall: 0.5756 - auc: 0.6085 - val_loss: 0.6731 - val_accuracy: 0.6079 - val_precision: 0.5713 - val_recall: 0.8648 - val_auc: 0.6440\n",
            "Epoch 8/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6755 - accuracy: 0.5896 - precision: 0.5931 - recall: 0.5708 - auc: 0.6207\n",
            "Epoch 8: val_accuracy improved from 0.60787 to 0.61250, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 49ms/step - loss: 0.6755 - accuracy: 0.5896 - precision: 0.5931 - recall: 0.5708 - auc: 0.6207 - val_loss: 0.6693 - val_accuracy: 0.6125 - val_precision: 0.5768 - val_recall: 0.8454 - val_auc: 0.6563\n",
            "Epoch 9/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5872 - precision: 0.5865 - recall: 0.5919 - auc: 0.6273\n",
            "Epoch 9: val_accuracy improved from 0.61250 to 0.62500, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 49ms/step - loss: 0.6725 - accuracy: 0.5872 - precision: 0.5865 - recall: 0.5917 - auc: 0.6274 - val_loss: 0.6595 - val_accuracy: 0.6250 - val_precision: 0.5908 - val_recall: 0.8130 - val_auc: 0.6665\n",
            "Epoch 10/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.6060 - precision: 0.6093 - recall: 0.5908 - auc: 0.6446\n",
            "Epoch 10: val_accuracy improved from 0.62500 to 0.63565, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.6671 - accuracy: 0.6060 - precision: 0.6093 - recall: 0.5908 - auc: 0.6446 - val_loss: 0.6530 - val_accuracy: 0.6356 - val_precision: 0.6038 - val_recall: 0.7889 - val_auc: 0.6755\n",
            "Epoch 11/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6623 - accuracy: 0.6158 - precision: 0.6179 - recall: 0.6055 - auc: 0.6545\n",
            "Epoch 11: val_accuracy did not improve from 0.63565\n",
            "113/113 [==============================] - 5s 49ms/step - loss: 0.6622 - accuracy: 0.6165 - precision: 0.6188 - recall: 0.6069 - auc: 0.6552 - val_loss: 0.6533 - val_accuracy: 0.6329 - val_precision: 0.6021 - val_recall: 0.7833 - val_auc: 0.6780\n",
            "Epoch 12/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.6290 - precision: 0.6285 - recall: 0.6291 - auc: 0.6706\n",
            "Epoch 12: val_accuracy improved from 0.63565 to 0.64213, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.6559 - accuracy: 0.6300 - precision: 0.6299 - recall: 0.6303 - auc: 0.6716 - val_loss: 0.6499 - val_accuracy: 0.6421 - val_precision: 0.6126 - val_recall: 0.7731 - val_auc: 0.6813\n",
            "Epoch 13/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6519 - accuracy: 0.6302 - precision: 0.6293 - recall: 0.6330 - auc: 0.6754\n",
            "Epoch 13: val_accuracy improved from 0.64213 to 0.64815, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.6518 - accuracy: 0.6306 - precision: 0.6298 - recall: 0.6333 - auc: 0.6758 - val_loss: 0.6498 - val_accuracy: 0.6481 - val_precision: 0.6212 - val_recall: 0.7593 - val_auc: 0.6809\n",
            "Epoch 14/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.6438 - precision: 0.6439 - recall: 0.6431 - auc: 0.6946\n",
            "Epoch 14: val_accuracy improved from 0.64815 to 0.65278, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 5s 49ms/step - loss: 0.6430 - accuracy: 0.6438 - precision: 0.6439 - recall: 0.6431 - auc: 0.6946 - val_loss: 0.6535 - val_accuracy: 0.6528 - val_precision: 0.6275 - val_recall: 0.7519 - val_auc: 0.6771\n",
            "Epoch 15/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.6524 - precision: 0.6465 - recall: 0.6722 - auc: 0.7005\n",
            "Epoch 15: val_accuracy did not improve from 0.65278\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.6378 - accuracy: 0.6524 - precision: 0.6465 - recall: 0.6722 - auc: 0.7005 - val_loss: 0.6536 - val_accuracy: 0.6491 - val_precision: 0.6381 - val_recall: 0.6889 - val_auc: 0.6755\n",
            "Epoch 16/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.6593 - precision: 0.6568 - recall: 0.6672 - auc: 0.7161\n",
            "Epoch 16: val_accuracy did not improve from 0.65278\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.6286 - accuracy: 0.6593 - precision: 0.6568 - recall: 0.6672 - auc: 0.7161 - val_loss: 0.6610 - val_accuracy: 0.6505 - val_precision: 0.6358 - val_recall: 0.7046 - val_auc: 0.6751\n",
            "Epoch 17/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.6725 - precision: 0.6709 - recall: 0.6772 - auc: 0.7266\n",
            "Epoch 17: val_accuracy improved from 0.65278 to 0.65787, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 5s 46ms/step - loss: 0.6202 - accuracy: 0.6725 - precision: 0.6709 - recall: 0.6772 - auc: 0.7266 - val_loss: 0.6580 - val_accuracy: 0.6579 - val_precision: 0.6489 - val_recall: 0.6880 - val_auc: 0.6840\n",
            "Epoch 18/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6747 - precision: 0.6700 - recall: 0.6886 - auc: 0.7338\n",
            "Epoch 18: val_accuracy did not improve from 0.65787\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.6131 - accuracy: 0.6747 - precision: 0.6700 - recall: 0.6886 - auc: 0.7338 - val_loss: 0.6663 - val_accuracy: 0.6569 - val_precision: 0.6486 - val_recall: 0.6852 - val_auc: 0.6824\n",
            "Epoch 19/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6011 - accuracy: 0.6935 - precision: 0.6888 - recall: 0.7074 - auc: 0.7500\n",
            "Epoch 19: val_accuracy improved from 0.65787 to 0.66528, saving model to /tmp/checkpoint\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.6015 - accuracy: 0.6928 - precision: 0.6874 - recall: 0.7072 - auc: 0.7493 - val_loss: 0.6723 - val_accuracy: 0.6653 - val_precision: 0.6472 - val_recall: 0.7269 - val_auc: 0.6846\n",
            "Epoch 20/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6007 - accuracy: 0.6862 - precision: 0.6778 - recall: 0.7105 - auc: 0.7468\n",
            "Epoch 20: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.6006 - accuracy: 0.6861 - precision: 0.6774 - recall: 0.7106 - auc: 0.7470 - val_loss: 0.6864 - val_accuracy: 0.6528 - val_precision: 0.6486 - val_recall: 0.6667 - val_auc: 0.6792\n",
            "Epoch 21/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7018 - precision: 0.6948 - recall: 0.7197 - auc: 0.7617\n",
            "Epoch 21: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.5881 - accuracy: 0.7018 - precision: 0.6948 - recall: 0.7197 - auc: 0.7617 - val_loss: 0.6897 - val_accuracy: 0.6588 - val_precision: 0.6455 - val_recall: 0.7046 - val_auc: 0.6849\n",
            "Epoch 22/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.7067 - precision: 0.6990 - recall: 0.7258 - auc: 0.7712\n",
            "Epoch 22: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.5795 - accuracy: 0.7067 - precision: 0.6990 - recall: 0.7258 - auc: 0.7712 - val_loss: 0.7075 - val_accuracy: 0.6481 - val_precision: 0.6416 - val_recall: 0.6713 - val_auc: 0.6793\n",
            "Epoch 23/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7164 - precision: 0.7088 - recall: 0.7344 - auc: 0.7793\n",
            "Epoch 23: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.5715 - accuracy: 0.7164 - precision: 0.7088 - recall: 0.7344 - auc: 0.7793 - val_loss: 0.7273 - val_accuracy: 0.6361 - val_precision: 0.6400 - val_recall: 0.6222 - val_auc: 0.6792\n",
            "Epoch 24/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.5626 - accuracy: 0.7207 - precision: 0.7164 - recall: 0.7300 - auc: 0.7883\n",
            "Epoch 24: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.5624 - accuracy: 0.7212 - precision: 0.7171 - recall: 0.7308 - auc: 0.7886 - val_loss: 0.7328 - val_accuracy: 0.6412 - val_precision: 0.6358 - val_recall: 0.6611 - val_auc: 0.6796\n",
            "Epoch 25/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.7258 - precision: 0.7184 - recall: 0.7428 - auc: 0.7970\n",
            "Epoch 25: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 45ms/step - loss: 0.5534 - accuracy: 0.7258 - precision: 0.7184 - recall: 0.7428 - auc: 0.7970 - val_loss: 0.7456 - val_accuracy: 0.6421 - val_precision: 0.6278 - val_recall: 0.6981 - val_auc: 0.6781\n",
            "Epoch 26/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.7339 - precision: 0.7281 - recall: 0.7467 - auc: 0.8035\n",
            "Epoch 26: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.5458 - accuracy: 0.7339 - precision: 0.7281 - recall: 0.7467 - auc: 0.8035 - val_loss: 0.7764 - val_accuracy: 0.6218 - val_precision: 0.6288 - val_recall: 0.5944 - val_auc: 0.6752\n",
            "Epoch 27/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.7382 - precision: 0.7295 - recall: 0.7572 - auc: 0.8088\n",
            "Epoch 27: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.5390 - accuracy: 0.7382 - precision: 0.7295 - recall: 0.7572 - auc: 0.8088 - val_loss: 0.7887 - val_accuracy: 0.6176 - val_precision: 0.6285 - val_recall: 0.5750 - val_auc: 0.6754\n",
            "Epoch 28/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.7409 - precision: 0.7317 - recall: 0.7601 - auc: 0.8132\n",
            "Epoch 28: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.5341 - accuracy: 0.7408 - precision: 0.7318 - recall: 0.7603 - auc: 0.8131 - val_loss: 0.7827 - val_accuracy: 0.6329 - val_precision: 0.6414 - val_recall: 0.6028 - val_auc: 0.6821\n",
            "Epoch 29/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.7528 - precision: 0.7491 - recall: 0.7616 - auc: 0.8252\n",
            "Epoch 29: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.5211 - accuracy: 0.7524 - precision: 0.7479 - recall: 0.7614 - auc: 0.8251 - val_loss: 0.8039 - val_accuracy: 0.6319 - val_precision: 0.6415 - val_recall: 0.5981 - val_auc: 0.6822\n",
            "Epoch 30/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7499 - precision: 0.7457 - recall: 0.7583 - auc: 0.8248\n",
            "Epoch 30: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 45ms/step - loss: 0.5196 - accuracy: 0.7499 - precision: 0.7457 - recall: 0.7583 - auc: 0.8248 - val_loss: 0.8504 - val_accuracy: 0.6148 - val_precision: 0.6165 - val_recall: 0.6074 - val_auc: 0.6594\n",
            "Epoch 31/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.7599 - precision: 0.7502 - recall: 0.7792 - auc: 0.8324\n",
            "Epoch 31: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.5100 - accuracy: 0.7599 - precision: 0.7502 - recall: 0.7792 - auc: 0.8324 - val_loss: 0.8501 - val_accuracy: 0.6157 - val_precision: 0.6233 - val_recall: 0.5852 - val_auc: 0.6650\n",
            "Epoch 32/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.7651 - precision: 0.7630 - recall: 0.7692 - auc: 0.8370\n",
            "Epoch 32: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 45ms/step - loss: 0.5038 - accuracy: 0.7651 - precision: 0.7630 - recall: 0.7692 - auc: 0.8370 - val_loss: 0.8502 - val_accuracy: 0.6204 - val_precision: 0.6252 - val_recall: 0.6009 - val_auc: 0.6742\n",
            "Epoch 33/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.7720 - precision: 0.7656 - recall: 0.7840 - auc: 0.8454\n",
            "Epoch 33: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.4927 - accuracy: 0.7721 - precision: 0.7658 - recall: 0.7839 - auc: 0.8453 - val_loss: 0.8716 - val_accuracy: 0.6194 - val_precision: 0.6311 - val_recall: 0.5750 - val_auc: 0.6709\n",
            "Epoch 34/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.4914 - accuracy: 0.7727 - precision: 0.7652 - recall: 0.7864 - auc: 0.8461\n",
            "Epoch 34: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 45ms/step - loss: 0.4914 - accuracy: 0.7725 - precision: 0.7654 - recall: 0.7858 - auc: 0.8461 - val_loss: 0.8927 - val_accuracy: 0.6176 - val_precision: 0.6185 - val_recall: 0.6139 - val_auc: 0.6627\n",
            "Epoch 35/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.4780 - accuracy: 0.7818 - precision: 0.7777 - recall: 0.7903 - auc: 0.8561\n",
            "Epoch 35: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.4783 - accuracy: 0.7814 - precision: 0.7766 - recall: 0.7900 - auc: 0.8559 - val_loss: 0.9313 - val_accuracy: 0.6014 - val_precision: 0.6229 - val_recall: 0.5139 - val_auc: 0.6576\n",
            "Epoch 36/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.7875 - precision: 0.7860 - recall: 0.7901 - auc: 0.8622\n",
            "Epoch 36: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 6s 50ms/step - loss: 0.4679 - accuracy: 0.7876 - precision: 0.7864 - recall: 0.7897 - auc: 0.8623 - val_loss: 0.9576 - val_accuracy: 0.6014 - val_precision: 0.6072 - val_recall: 0.5741 - val_auc: 0.6492\n",
            "Epoch 37/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.7908 - precision: 0.7865 - recall: 0.7983 - auc: 0.8668\n",
            "Epoch 37: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.4616 - accuracy: 0.7908 - precision: 0.7865 - recall: 0.7983 - auc: 0.8668 - val_loss: 0.9710 - val_accuracy: 0.6148 - val_precision: 0.6220 - val_recall: 0.5852 - val_auc: 0.6592\n",
            "Epoch 38/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.7928 - precision: 0.7891 - recall: 0.7992 - auc: 0.8718\n",
            "Epoch 38: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 47ms/step - loss: 0.4534 - accuracy: 0.7928 - precision: 0.7891 - recall: 0.7992 - auc: 0.8718 - val_loss: 0.9696 - val_accuracy: 0.6204 - val_precision: 0.6519 - val_recall: 0.5167 - val_auc: 0.6651\n",
            "Epoch 39/40\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.7943 - precision: 0.7908 - recall: 0.8003 - auc: 0.8718\n",
            "Epoch 39: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 45ms/step - loss: 0.4533 - accuracy: 0.7943 - precision: 0.7908 - recall: 0.8003 - auc: 0.8718 - val_loss: 1.0020 - val_accuracy: 0.6060 - val_precision: 0.6155 - val_recall: 0.5648 - val_auc: 0.6496\n",
            "Epoch 40/40\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.8051 - precision: 0.8047 - recall: 0.8059 - auc: 0.8809\n",
            "Epoch 40: val_accuracy did not improve from 0.66528\n",
            "113/113 [==============================] - 5s 48ms/step - loss: 0.4382 - accuracy: 0.8051 - precision: 0.8045 - recall: 0.8061 - auc: 0.8812 - val_loss: 0.9981 - val_accuracy: 0.6116 - val_precision: 0.6197 - val_recall: 0.5778 - val_auc: 0.6537\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eea895d5b10>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hybridmodel.fit(x=[Xeeg_trainS_3D, Xfnirs_trainS_3D], y=Y_train, validation_data=([Xeeg_testS_3D, Xfnirs_testS_3D], Y_test), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gbs7mBP3vjwx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbs7mBP3vjwx",
        "outputId": "40c6071c-e550-466d-c647-f1667e61e7fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ee9c00821a0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hybridmodel.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803b81ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "803b81ce",
        "outputId": "a0d96c02-d86b-483c-9e2d-d93a324106c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68/68 [==============================] - 1s 12ms/step\n"
          ]
        }
      ],
      "source": [
        "probabilities = hybridmodel.predict([Xeeg_testS_3D, Xfnirs_testS_3D])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0d2ccd",
      "metadata": {
        "id": "4c0d2ccd"
      },
      "outputs": [],
      "source": [
        "y_preds= np.round(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49bbf264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "49bbf264",
        "outputId": "54370272-3982-4c5b-cb41-8ae4b5e72222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(17.25, 0.5, 'Actual label')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAF7CAYAAAAzPisLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApXklEQVR4nO3deVxU9f7H8ffMICg7CMhVAUUF01RAcQEVRXPDLa8KmbuZ11zKx6+bdlUq65qZS6mZS+YuWDcVkNzQRBNFKxST3ECRTWSRVfY5vz+4zm0CFIdhWL7v5+Ph48Y5Zw6fQ90X45kzZ2SSJEkgIqJGTV7XAxARUe1j7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgHo1fUAdcV58Ym6HoEEsHWme12PQAIY4Gz53G34zJ6ISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiASgV9cDUN3o1NIEC15pD7c2FjDQkyMh8wm+i0zE3ogHAIA9b7qjVzvLCo87fysdb3z7q+rrLq1NMbZ7K/RqZ4lWFk2R9aQE1x5k44sTd3A//YnOjofqvx+/24WgfVvR0t4RH2zaDwAoLirEhbCjuBZ5HknxsSgqLICNbSv0GzoW/YaOgVyhUNtHdmY6gg98gz+uXkZOVgbMLK3RrVc/jJgwHcamZnVxWA0GYy8gzw7NsWW6G2KSc7D5dCyeFJfB3rIZbM2aqm2XklWAdcfvqC17lFOk9vUbA9rCzcECx68/xK2UXFibGOB1D3scWtgHvl9F4k5qXq0fD9V/j9Mf4dj3u2HQtJna8rSHSTi4bR06du2BwWP80MzQCDd+i8SBLZ8j7tbvmLHIX7VtYcETfPbebBQVFsJrxDhYWrVAwr07OBv6H9yO/hX/Wr8LcjlPVlSFsReMkYECn/l2wdmbaVi47yokqeptcwtLERyV8sz97Tofj3cDolFS9r8d/XjtIUIWeeDNAW3xz4PXtTU6NWD/2bkRbZ07Q1IqkZeTrVpuZtEc/hv3oaW9o2pZ/2GvYveXnyDidCh8fGfApqUdACD68nlkPHqI+cvXoIu7p2p7IxNThAZ+i8R7d2Dfzll3B9XA8NegYEa5/A3WJgZYf+IOJAlo1kQBmazq7RVyGQz1FVWuj4rPUgs9AMRnPMGd1Dw42hhpa2xqwG7/HoXfLvwE3zfeqbDO2NRcLfRPufTxAgCkJN5XLSt4kg8AMDFXP71oZtEcAKBvYKCliRsnPrMXTJ8OzZFbWIIWpgbYPNUVba2NkF9UiuDfkrHy6C0UlypV27axMsLVjwdDX0+OtNwifH85EV+FxaJU+Yy/DvyXlYkBT+EQlGVlOLhtHfoOGYVWbdpX+3E5jzMBlP8yeKpDZ1fI5HJ8t309xs9cCAsrGyTev4tj3++GS+/+sG3dRsvTNy6MvWDaNDeCQi7D5mmu+M+VJKw9dhs921liqqcDTJo1wf8FRAMAEjKfIDIuE7dTcmGor8DQLrZ4a1A7tLEyxKID0c/8HqNd/wZbs6bYcPKuLg6J6rHw44eRkfYQ73y8odqPKS0pwengg7Bq0RJtOrykWt7Svi0mv7UYP+zchM/em61a3sd7BKYseF+rczdG9S72aWlpuHDhAuLi4pCVlQUAMDc3h6OjIzw9PWFtbV23AzZwhgYKGOrrIeDiA/w7+CYA4NSNR9BXyOHX2w4bTt5FfMYTLP3PDbXHBUWlYMW4TvDtZYddP8fj2oPsynYPR2sj+I99Cb/FP8bhX5Nq/Xio/srLyUbIge3wmTgDJmYW1X5cwNa1SEm4h/n+a6FQqCfKvLk12jh1wsvd+6C5jS3u3LiGM0e/g7GpGcbPXKjtQ2hU6k3sS0pK8NlnnyEwMBBlZWWwtraGmVn5pVTZ2dlIS0uDQqGAn58flixZAj29ejN6g1JYUgYAOHrtodrykKsp8OttBxcHc8RnVH7J5M5z9+Hbyw4e7ZtXGnsrY31sneGG3MJSvL33GqpxtocasaB9W2FkbIqBIydU+zEnDu3DzyeDMPr1N9Glh4faursx1/DVx//E4s+3q57xu/T2QlNDI4QG7oDH4FFoad9Wq8fQmNSbYn7xxRcICgqCv78/hg8fDhMTE7X1eXl5OHbsGD7//HM0bdoU7777bh1N2rA9yimCk60JMnLVL6HMzCsGAJg1q/o/iZTswvJtDJtUWGfcVA/bZ3aHSVM9vL7lMh79Zf8kltTkBJw/GYSJb7yDrMx01fKS4mKUlZUiPTUFzQwNYWTyv2vjI06H4vDuzeg/7FX4+M6osM/zJ47A1NxC7dQOAHTr2RdHA75B3M3rjP0z1JvYBwUF4f3338e4ceMqXW9sbIwJEyZALpdj/fr1jL2GbiTloK+TFVqYNcW9P73pyca0/EqGzPySKh9rZ2lYvs1/fzE8pa8nx5ZprmhjbYgZ239B7KP8WpicGpKsjDRISiUObluHg9vWVVi/dPY4eI+aCN/ZiwAAVy+dw96Nn8K1zwC89o/K/7+dk/UYSqWywvKyslK1/6XK1ZvY5+fnw9bW9rnb2draIj+fMdHUseiHmDPQEePdW+FSbKZq+Xj31igpU+JybCaMDBQoLlVWuKRy7qDyS+R+vv2/Z2pyGfDFpG5wcTDHW7ujcLWKc/kkllYOjpj7r1UVlgft24bCgifwnf0OrG1bASi/NPObNcvRobMLZv7fh1W+McqmpR1ioiJx6/pvcO7iplp+5dwpAIC9I6+xf5Z6E3sXFxds2bIFXbp0qXAK56m8vDxs2bIFrq6uOp6u8fgjORf/uZKI8e6toZDLcCXuMXq2s8TwrrbYciYOj3KL0NPRAmtf64bQayl4kP4EBk3keKVzC3Rva4HAyATEJOeq9rdkZEcM6myDMzGPYG7YBKNd/6b2/Z73pixqnIxNzeHS26vC8tPBBwFAtS7jUQo2//s9ADK4eQ7Erz+fUdu+dZv2aN22/JLNgT7jcfF0KL765J8Y6DMezW1scfv3KFw5dwovufREW+fOtXtQDVy9if3y5csxbdo0eHl5wcPDA46Ojqro5+XlIS4uDhERETAyMsKuXbvqdtgG7oNDMUjOKsS47q0wuHMLJGcVYGXITez+OR4AkPy4EL/ef4xXOtvAysQASklC3KN8+B+6gYORiWr76vi38n9H3p1s4N3JpsL3YuzpWdJTU1CQX/5+jIAtayqsH+k3SxV729YO+Ne6nQjatxWRZ08gJysD5pZWeOXVSRg9aXaFx5I6mSQ96w3zupWTk4OAgACcP38ecXFxyMnJAQCYmprC0dER/fv3h5+fH0xNTWv8vZwXn6jxPoieZ+tM97oegQQwwLniTQv/ql7FXpcYe9IFxp50oTqx571xiIgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAtCrzkbe3t6QyWQvtGOZTIawsDCNhiIiIu2qVux79uz5wrEnIqL6o1qxX7VqVW3PQUREtYjn7ImIBKBx7PPy8rBt2zbMmjULY8eORXR0NAAgKysLO3fuRHx8vNaGJCKimqnWaZy/evjwISZPnoyHDx/CwcEBcXFxyM/PBwCYm5sjMDAQSUlJWLZsmVaHJSIizWgU+9WrVyM/Px9HjhyBpaUlPDw81NYPHjwYZ8+e1cZ8RESkBRqdxrlw4QKmTJmC9u3bV3qVjp2dHVJSUmo8HBERaYdGsS8sLISlpWWV65+e0iEiovpBo9i3a9cOV65cqXJ9WFgYOnXqpPFQRESkXRrFftq0afjxxx+xbds25OXlAQAkSUJ8fDz++c9/4urVq5g+fbo25yQiohrQ6AXaMWPGIDk5GV9++SW++OILAMAbb7wBSZIgl8uxaNEiDB48WJtzEhFRDWgUewCYO3cuxowZg5MnTyI+Ph5KpRL29vYYMmQI7OzstDkjERHVkMaxB4CWLVvydA0RUQNQo9jfvn0b4eHhSEpKAgC0bt0a/fr1g7Ozs1aGIyIi7dAo9sXFxfD390dQUJDqPD0AKJVKrF27FqNGjcInn3wCfX19rQ5LRESa0Sj2n3/+OY4cOYJJkyZh8uTJsLe3h0wmQ3x8PPbu3YuAgACYmZlh6dKl2p6XiIg0oNGll8HBwRgzZgz8/f3h6OgIPT09KBQKODo64oMPPsCoUaMQHBys7VmJiEhDGsW+tLQU3bp1q3K9q6srysrKNB6KiIi0S6PY9+3bFz///HOV68+fPw9PT0+NhyIiIu2qVuyzsrLU/rz99ttITEzE/PnzcfHiRSQlJSEpKQkRERGYN28ekpOT8fbbb9f27EREVE3VeoG2d+/eFe5uKUkSbt++jdOnT1dYDgAjR45ETEyMlsYkIqKaqFbs582bxw8cJyJqwKoV+wULFtT2HEREVIv4geNERAKo0e0Sfv31V8TExCA3NxdKpVJtnUwmw7x582o0HBERaYdGsc/KysKcOXMQHR0NSZIgk8lUL8w+/WfGnoio/tDoNM7q1atx69YtrF27FmFhYZAkCTt27MCJEyfg5+eHl156CefPn9f2rEREpCGNYn/u3Dn4+vpixIgRMDIyKt+RXA4HBwd88MEHaNWqFVauXKnVQYmISHMaxT4nJwft27cHAFXs//wh456ens98hy0REemWRrG3sbFBeno6AEBfXx/NmzfHzZs3VetTU1N5XT4RUT2i0Qu07u7uiIiIwNy5cwEAw4cPx44dO6BQKKBUKrF7927069dPq4MSEZHmNIr99OnTERERgeLiYujr62PBggW4e/cuvvzySwDlvwyWLVum1UGJiEhzGsXe2dlZ7aMHzczMsGvXLuTk5EAul8PY2FhrAxIRUc3V6E1Vf2VqaqrN3RERkZZUK/ZHjhzRaOdjx47V6HFERKRd1Yr9kiVLXnjHMpmMsSciqieqFfu/3rOeiIgalmrFvlWrVrU9BxER1SLe4piISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJQCY9/TzBZ9i0adOL77iefyxhYWldT0AisHCfX9cjkAAKop7f6GrFvmPHji/8zWUyGf74448XfpyuMPakC4w96UJ1Yl+tN1X9+YNJiIio4eE5eyIiATD2REQC0Ph+9jdv3sS+ffsQExOD3NxcKJVKtfUymQxhYWE1HpCIiGpOo2f2kZGRmDBhAs6ePQsbGxskJCTAzs4ONjY2SE5OhqGhIdzd3bU9KxERaUij2G/YsAF2dnY4fvw4Vq5cCQCYM2cOAgICEBgYiNTUVAwbNkyrgxIRkeY0in1MTAzGjx8PY2NjKBQKAFCdxunWrRt8fX1VHz5ORER1T6PYKxQKGBkZASj/3Fk9PT1kZGSo1tvZ2SE2NlY7ExIRUY1pFHt7e3vcv38fQPkLsY6Ojmovxp49exZWVlZaGZCIiGpOo9h7eXkhNDQUpaXlb0OdMWMGTp48iSFDhmDIkCE4c+YMfH19tTooERFprlq3S/irkpIS5OXlwdzcHDKZDAAQFBSEkydPQqFQYMCAARg3bpzWh9Um3i6BdIG3SyBd0Nq9cRojxp50gbEnXahO7PkOWiIiAWj0DtqpU6c+dxuZTIbdu3drsnsiItIyjWJf2ZkfpVKJ5ORkpKSkwMHBATY2NjUejoiItEOj2O/du7fKdT/99BOWL1+O999/X+OhiIhIu7R+zn7gwIEYPXq06jYKRERU92rlBVp7e3tcv369NnZNREQa0HrsS0tLcezYMVhYWGh710REpCGNztlXdT4+NzcXV69eRXp6OpYsWVKjwYiISHs0in1kZGSFZTKZDGZmZujevTsmTJiAvn371ng4IiLSDo1if+bMGW3PQUREtUijc/ZHjhxBYmJilesTExNx5MgRTWciIiIt0yj277//PqKioqpcHx0dzevsiYjqEY1i/7x7pz158kT1CVZERFT3qn3O/ubNm7h586bq619++QVlZWUVtsvJyUFgYCDatm2rnQmJiKjGqh37sLAwbNpUfhtNmUyGgwcP4uDBg5Vua2pqis8++0w7ExIRUY1VO/YTJ07EgAEDIEkSJkyYgIULF6J///5q28hkMjRr1gz29vbQ09PoQh8iIqoF1S6yjY2N6k6We/bsQfv27WFpaVlrgxERkfZo9AKtk5MTHj16VOX6W7duITs7W+OhiIhIuzSK/aeffgp/f/8q13/wwQc8Z09EVI9oFPtLly7B29u7yvUDBw7ExYsXNR6KiIi0S6PYZ2ZmPvOulubm5sjIyNB4KCIi0i6NYm9tbY2YmJgq19+4cYMv3hIR1SMaxX7w4MH44YcfcPr06QrrwsLCcOjQIQwePLjGwxERkXbIpOfd+6ASubm5mDRpEu7evYuOHTuiQ4cOAIA7d+7g5s2baNeuHQ4cOABTU1OtD6wthaV1PQGJwMJ9fl2PQAIoiNr03G00ij1Qfv+bb775BqdOncKDBw8AlH8c4ZAhQzBr1iwYGhpqsludYexJFxh70oVajf3zZGdnw8zMrDZ2rRWMPekCY0+6UJ3Ya/UzaIuLi3Hs2DG89dZb/KQqIqJ6pMY3sJEkCRcvXkRISAhOnTqFvLw8WFpaYuTIkdqYj4iItEDj2P/+++8ICQlBaGgo0tPTIZPJMGLECEyePBkuLi6QyWTanJOIiGrghWKfkJCA4OBghISEID4+Hi1atMCoUaPQtWtXLFq0CEOHDoWrq2ttzUpERBqqdux9fX0RHR0NCwsLDB06FJ988gl69OgBAKqrcYiIqH6qduyvXbuG1q1bY8mSJRgwYADvV09E1IBU+2qc5cuXw9raGvPnz4enpyf8/f1x6dKl534eLRER1b1qPz1//fXX8frrryMhIQEhISE4evQovvvuO1hZWaFXr16QyWR8UZaIqJ6q0Zuqnl6R8+OPPyItLQ1WVlYYOHAgvL294eHhAQMDA23OqlV8UxXpAt9URbqgs3fQKpVKXLp0CcHBwTh16hTy8/PRrFkzREVF1XTXtYaxJ11g7EkX6uR2CUVFRTh9+jRCQkLw9ddfa3PXWsXYky4w9qQLdXpvnPqOsSddYOxJF3R+bxwiIqqfGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIB6NX1AKRbv1+PRnDQEVy5HInk5CSYm5mja7dumLfwHbRp01Zt24D9+3AwcD8SExJgbmGBocNGYN6Ct2FoaKjaJikpESOGDKr0e636fB2Gj/Cp1eOh+mnbR5MxZXTvKte3G7IUyWnZkMlkmPV3T7wxvi/a2Vkjv6AIV28mYNX247h07Z5q+37dO+DkN29Xui+vqWtw+fp9bR9Co8PYC2bnjm9wNeo3vDJ0GJycnJGenobAA/vhN34c9gYcRIcOTgCA9Ws/x65vv8ErQ4Zi0uSpiIuNReCBfYi9exdbtu+osN/hI0aib//+asu6ubjo4pCoHtrxwwWcibyltkwmAzYu9UN8ciaS07IBAJ8uGou3pwzCgaOXse278zA3aYZZf/fEye3vwHvGOvxyI15tH18d+Am/3Higtiw2Ia12D6aRYOwFM2XadKxavQZN9PVVy4YOH4HxY0fh22+24dPP1iAt7RH27dmFkaPH4N+frlZt5+DQBqtWfoyzP53BgIHeavt9qVMnjBw1RmfHQfVbZPQ9REbfU1vm4eIIo2YGCPzxCgBAoZBj9vh+OHTqN8xavke13Q+nonAz9CP4jehRIfYXomJxOOxqrc/fGPGcvWBcXN3UQg+UR7xd+w64FxcHALh29SpKS0sxbLj6KZhhI0YAAE4cC61030+ePEFJcXEtTE2NwcThPaBUKnHw2C8AgCZ6Chg208ejjFy17dIyc1FWpkRBUUml+zE2NIBCwXS9KP7ECJIkISMjHebmFgCgCraBgYHadk2bNgMAxMTcqLCPLZs3oY+7K9zdumLSxL8j4sLPtTw1NSR6enL8/RU3XLp2Dw9SMgEAhUUluBx9D5NH94bf8B6ws7XAyx1aYvuKyXic8wQ7frhQYT9bP5yMtAtrkXVpPY5vWwi3Tva6PpQGi6dxCKFHg/EoNRVvzV8IAGjTtvyF2qtRv6Fnr/+9yPbbr+XPyB6lpqqWyWVy9PHoC+/Bg2Fj0wJJiQnYu3sX5v1jNr7c9DX6ew3Q3YFQvfVKn06wsjDGiq+Pqi2fsWw39q6aiZ0rp6uWxSWkwXvGOtxPylAtKyktxeGwKBz/+QYysvLxkqMt3p4yCGE73sHA6etw7Vairg6lwZJJkiTV9RAv4vHjx7h79y7c3d1rtJ/CUi0N1MDdi4vF5Ncmol37Dti5Zz8UCgUAYPJrExF79w4W/2sZ3Hv2wr24WPx7xUd49OgRJEmJ36JjqtxndlYWXh3tAxNTEwQdPa6rQ6mXLNzn1/UI9cKuldPx6mAXtH1lKTKz81XLbSxNsHLRWOTmFeKny7fQwsoU784YgicFxRg8az0ysvKr3KejnRWuHPwXfv7tLsbM36yLw6i3CqI2PXebBnca5/Lly5g6dWpdj9EopKelYf5bc2BsbII1679UhR4A1n6xEU7OHfHBsn9hxJBBWDhvLoYMHYaOL72kdullZczMzTHm1XG4f+8eUh8+rO3DoHrOqJk+Rg7oglMRf6iFXqGQI3TLAuTkFWLRZ98j+KdobP/+Z4z4x0Y42llh0dTBz9xvXEI6joZHw8u9A+RyWW0fRoPH0ziCys3NxVv/mI3cnFzs3LMfNjYt1Na3aNECu/cFID7+PjLS02Fv7wAra2sMHtAX9g5tnrt/W1tbAEB2dhZa/PefSUyjBnaDUTMD1QuzT/V1a4+XO7TE4rWH1JbHPkjDzXsP0cfF8bn7Tnz4GAb6TWDUzAC5+YVanbuxqTexHzVqVLW2y8+v+q91VD1FRUVYOO8fiI+/j23f7ES79u2r3NbBoQ0c/hv32Lt3kZaWhtFjxz33eyQmlp9DtbC01MrM1HD5jeiB3PxCHA2PVlveorkJAEChqPisvImeAnrVuOKmbWsrFBQWI+9JkXaGbcTqTezj4uLQvn17dOrU6ZnbJSUlISUlRUdTNT5lZWV47//eQfS1q/hi42Z0c3Gt1uOUSiXWr/scTZs1w4SJfqrlmZmZsPxL0FNTU3Hk0A9wcnKGtbWNVuenhsXKwhjePTviuxO/oKBQ/VLKO/GPAAAThnbHqYg/VMtdOraGk0ML7Dh0QW0/6Y/z1B7fxakVfLy64MSFGDSwlx7rRL2JfYcOHeDg4IBPP/30mdudOHECV65c0dFUjc/a1atw9qcz8BowENnZWTgaEqS2/ukboz779BMUFRWjY8eOKCktxbHQo/j9ejQ+XrkKf2vZUrX9+rWfIzHhAXr17gNraxskJyfhP98FoqDgCd57f6lOj43qn/FD3NCkiQKBP/5SYV3UHwkIu/gHpozuDVOjpgi7dBO2VqaY6+eFgqISbNr/k2rbvatmoKCoBJeu3UNaZi5ecrTFzL974klhMZZvCKqwb6qo3sS+a9euOH/+fLW25W9xzd26dRMAEH72J4Sf/anC+qex79ixE/bv3Y0fj4ZALpfh5S5dsW3HLrVLMQHAw8MT33+XgMCA/cjNyYGJiQncerjjzTlz8VKnzrV/QFSv+Y1wR2pGDs5E3qx0/YRF2/DO1EGYMLQ7XvHohOLSUlz4LRYrNh9VPfMHgJCz0fAb7o6Fk71hatQU6Vl5CDp9Df/e9iPiEtJ1dTgNWr259PLBgwe4c+cOBg2q/KZaTxUWFiIjIwOtWrWq0ffjpZekC7z0knShOpde1ptn9vb29rC3f/674Zo2bVrj0BMRiabBXWdPREQvjrEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIBMPZERAJg7ImIBMDYExEJgLEnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRAGSSJEl1PQQREdUuPrMnIhIAY09EJADGnohIAIw9EZEAGHsiIgEw9kREAmDsiYgEwNgTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD29EyxsbGYMWMGXFxc4OnpidWrV6O4uLiux6JGJj4+Hv7+/hgzZgw6deqEkSNH1vVIjY5eXQ9A9Vd2djamTZuGNm3aYOPGjUhNTcWqVatQWFgIf3//uh6PGpE7d+4gPDwc3bp1g1KpBO+8rn2MPVUpMDAQ+fn52LRpE8zNzQEAZWVl+OijjzBnzhy0aNGibgekRsPb2xuDBw8GACxZsgS///57HU/U+PA0DlXp3Llz6NOnjyr0ADB8+HAolUpcuHCh7gajRkcuZ4pqG3/CVKW4uDg4OjqqLTM1NYW1tTXi4uLqaCoi0gRjT1XKycmBqalpheVmZmbIzs6ug4mISFOMPRGRABh7qpKpqSlyc3MrLM/OzoaZmVkdTEREmmLsqUqOjo4Vzs3n5uYiLS2twrl8IqrfGHuqUv/+/REREYGcnBzVsuPHj0Mul8PT07MOJyOiF8Xr7KlKfn5+2Lt3L+bNm4c5c+YgNTUVq1evhp+fH6+xJ60qKChAeHg4ACApKQl5eXk4fvw4AKBnz56wtLSsy/EaBZnEt6rRM8TGxuLjjz9GVFQUjIyMMGbMGCxatAj6+vp1PRo1IomJiRg0aFCl6/bs2YNevXrpeKLGh7EnIhIAz9kTEQmAsSciEgBjT0QkAMaeiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2JNQvL29sWTJEtXXkZGRcHZ2RmRkZB1Ope6vM1bF2dkZGzdufOH9Hzp0CM7Ozrh+/bom41Vq48aNcHZ21tr+SPsYe9KZp5F5+qdLly4YOnQoVqxYgfT09Loe74WEh4drFFqiusIboZHOLVy4EK1bt0ZxcTF+/fVXBAQEIDw8HEePHkWzZs10Oou7uzuio6PRpEmTF3pceHg49u/fjwULFtTSZETaxdiTzvXv3x9dunQBAEyYMAHm5ubYuXMnTp8+jZEjR1b6mCdPnsDQ0FDrs8jlchgYGGh9v0T1DU/jUJ3r3bs3gPI7HwLAkiVL4OrqigcPHmD27NlwdXXFu+++CwBQKpXYtWsXfHx80KVLF3h4eMDf37/CZ+JKkoTNmzejf//+6NatG6ZMmYI7d+5U+N5VnbO/du0aZs+eDXd3d7i4uGDUqFHYvXu3ar79+/cDgNppqae0PWN1JSUl4cMPP8TQoUPRtWtX9OrVCwsXLlT9XP+qsLAQ/v7+6NWrF9zc3PDee+9V+tnC4eHhmDRpElxcXODq6oo333yzRnNS3eAze6pzDx48AACYm5urlpWWlmLWrFno3r07Fi9ejKZNmwIA/P39cfjwYYwbNw5TpkxBYmIi9u/fj5iYGAQEBKhOx3z55Zf4+uuv4eXlBS8vL9y4cQMzZ85ESUnJc+e5cOEC5syZAxsbG0ydOhVWVlaIjY3F2bNnMW3aNPj6+uLRo0e4cOECVq9eXeHxupixMtevX0dUVBR8fHxga2uLpKQkBAQEYOrUqQgNDa1wimzFihUwNTXF/Pnzce/ePQQEBCA5ORl79+6FTCYDABw5cgRLlixB37598e6776KgoAABAQGYNGkSDh8+jNatW2s0K9UBiUhHfvjhB8nJyUmKiIiQMjIypJSUFCk0NFTq2bOn1LVrV+nhw4eSJEnS4sWLJScnJ2nNmjVqj79y5Yrk5OQkBQcHqy0/d+6c2vKMjAypc+fO0ptvvikplUrVduvWrZOcnJykxYsXq5ZdunRJcnJyki5duiRJkiSVlpZK3t7e0sCBA6Xs7Gy17/PnfX300UeSk5NThWOsjRmr4uTkJG3YsEH1dUFBQYVtoqKiJCcnJ+nw4cOqZU//Pbz66qtScXGxavn27dslJycnKSwsTJIkScrLy5N69OghLVu2TG2faWlpUvfu3dWWb9iwodKfB9UfPI1DOjd9+nT06dMHXl5eWLRoEYyMjLBp06YKn3712muvqX19/PhxmJiYwNPTE5mZmao/nTt3hqGhoepUTEREBEpKSjB58mTVM1QAmDZt2nNni4mJQWJiIqZOnQpTU1O1dX/eV1V0MWNVnv7tBwBKSkrw+PFj2Nvbw9TUFDExMRW29/X1VXth+rXXXoOenp7qE6OefiSlj4+P2rHI5XJ069atXl2uSs/H0zikc/7+/mjbti0UCgWsrKzQtm1byOXqzzv09PRga2urtiw+Ph65ubno06dPpfvNyMgAACQnJwMA2rRpo7be0tISZmZmz5wtISEBAODk5FTt49H1jFUpLCzE1q1bcejQIaSmpkL60+cS5ebmVtjewcFB7WsjIyNYW1sjKSkJAHD//n0AVf8CMjY21mhOqhuMPelc165dVVfjVEVfX7/CLwClUonmzZtjzZo1lT6mPnxOaV3O+PHHH+PQoUOYNm0aXFxcYGJiAplMhkWLFqmFv7qePmb16tWwtrausF6hUNR4ZtIdxp4aDHt7e1y8eBFubm5qpyz+qmXLlgDKn5na2dmplmdmZlZ6tcmfPd3+9u3b8PDwqHK7qk7p6GLGqpw4cQJjx45Ve/dtUVFRpc/qgfK/hTy9EgoA8vPzkZaWhv79+wP438+iefPmz/xZUMPAc/bUYAwfPhxlZWXYvHlzhXWlpaXIyckBAHh4eKBJkybYt2+f2jPap5dOPkvnzp3RunVr7NmzR7W/p/68r6dXtvx1G13MWJXKnmnv3bsXZWVllW5/8OBBtSt/AgICUFpaqop9v379YGxsjK1bt1Z6hVBmZqbGs5Lu8Zk9NRg9e/aEr68vtm7dij/++AOenp5o0qQJ7t+/j+PHj2Pp0qUYNmwYLC0tMXPmTGzduhVz5syBl5cXYmJicO7cOVhYWDzze8jlcnz44YeYO3cuxo4di3HjxsHa2hpxcXG4e/cuduzYAaD8lwIAfPLJJ+jbty8UCgV8fHx0MmNVBgwYgKCgIBgbG6N9+/a4evUqIiIi1C5p/bOSkhJMnz4dw4cPx71793DgwAF0794dgwYNAlB+Tv7DDz/Ee++9h3HjxmHEiBGwtLREcnIywsPD4ebmBn9/f41mJd1j7KlBWbFiBV5++WUEBgZi/fr1UCgUaNWqFUaPHg03NzfVdu+88w709fURGBiIyMhIdO3aFd9++y3mzJnz3O/Rr18/7N69G1999RW+/fZbSJIEOzs7TJw4UbXNkCFDMGXKFISGhiI4OBiSJMHHx0dnM1Zm6dKlkMvlCAkJQVFREdzc3LBz50688cYblW7v7++PkJAQbNiwASUlJfDx8cGyZcvUTlGNGjUKNjY22LZtG3bs2IHi4mK0aNECPXr0wLhx4zSak+qGTNLklRsiImpQeM6eiEgAjD0RkQAYeyIiATD2REQCYOyJiATA2BMRCYCxJyISAGNPRCQAxp6ISACMPRGRABh7IiIBMPZERAL4f4WJNWlsl+PlAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "\n",
        "mat = confusion_matrix(Y_test, y_preds )\n",
        "labels = [0,1]\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('Actual label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc3b1a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cc3b1a6",
        "outputId": "23a088e2-d4ad-4220-df2f-4e1e0fd86dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 0.6723 - accuracy: 0.6653 - precision: 0.6472 - recall: 0.7269 - auc: 0.6846\n"
          ]
        }
      ],
      "source": [
        "#model performance on unseen data\n",
        "loss,accuracy,precision,recall,AUC = hybridmodel.evaluate([Xeeg_testS_3D,Xfnirs_testS_3D], Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sorzoJrruGTQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sorzoJrruGTQ",
        "outputId": "5376c8bf-5ff8-4137-8eb0-9c2b6a0b1310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline model= False\n",
            "resnet= False\n",
            "seed= 38\n",
            "lr= 5e-05\n"
          ]
        }
      ],
      "source": [
        "print(\"baseline model=\", baseline_model)\n",
        "print(\"resnet=\", resnet)\n",
        "print(\"seed=\",RANDOM_STATE)\n",
        "print(\"lr=\", lr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
